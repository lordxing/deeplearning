{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.7.10","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# Import necessary packages.\nimport numpy as np\nimport torch\nimport torch.nn as nn\nimport torchvision.transforms as transforms\nfrom PIL import Image\n# \"ConcatDataset\" and \"Subset\" are possibly useful when doing semi-supervised learning.\nfrom torch.utils.data import ConcatDataset, DataLoader, Subset, Dataset\nfrom torchvision.datasets import DatasetFolder\n\n# This is for the progress bar.\nfrom tqdm.auto import tqdm","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2021-09-15T08:42:32.856535Z","iopub.execute_input":"2021-09-15T08:42:32.856926Z","iopub.status.idle":"2021-09-15T08:42:34.261857Z","shell.execute_reply.started":"2021-09-15T08:42:32.856845Z","shell.execute_reply":"2021-09-15T08:42:34.260958Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# It is important to do data augmentation in training.\n# However, not every augmentation is useful.\n# Please think about what kind of augmentation is helpful for food recognition.\ntrain_tfm1 = transforms.Compose([\n    # Resize the image into a fixed shape (height = width = 128)\n    transforms.Resize((128, 128)),\n    # You may add some transforms here.\n    # ToTensor() should be the last one of the transforms.\n    transforms.ToTensor(),\n])\n\ntrain_tfm2 = transforms.Compose([\n    # Resize the image into a fixed shape (height = width = 128)\n    transforms.Resize((128, 128)),\n    # You may add some transforms here.\n    # ToTensor() should be the last one of the transforms.\n    transforms.RandomHorizontalFlip(p=0.6),\n    transforms.ColorJitter(brightness=0.5),\n    transforms.RandomRotation(30),\n    transforms.ToTensor(),\n])\n\n\n\n# We don't need augmentations in testing and validation.\n# All we need here is to resize the PIL image and transform it into Tensor.\ntest_tfm = transforms.Compose([\n    transforms.Resize((128, 128)),\n    transforms.ToTensor(),\n])\n","metadata":{"execution":{"iopub.status.busy":"2021-09-15T08:42:34.263454Z","iopub.execute_input":"2021-09-15T08:42:34.263835Z","iopub.status.idle":"2021-09-15T08:42:34.27306Z","shell.execute_reply.started":"2021-09-15T08:42:34.263788Z","shell.execute_reply":"2021-09-15T08:42:34.272171Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Batch size for training, validation, and testing.\n# A greater batch size usually gives a more stable gradient.\n# But the GPU memory is limited, so please adjust it carefully.\nbatch_size = 128\n\n# Construct datasets.\n# The argument \"loader\" tells how torchvision reads the data.\ntrain_set1 = DatasetFolder(\"../input/ml2021spring-hw3/food-11/training/labeled\", loader=lambda x: Image.open(x), extensions=\"jpg\", transform=train_tfm1)\ntrain_set2 = DatasetFolder(\"../input/ml2021spring-hw3/food-11/training/labeled\", loader=lambda x: Image.open(x), extensions=\"jpg\", transform=train_tfm2)\ntrain_set = ConcatDataset([train_set1, train_set2])\nvalid_set1 = DatasetFolder(\"../input/ml2021spring-hw3/food-11/validation\", loader=lambda x: Image.open(x), extensions=\"jpg\", transform=train_tfm1)\nvalid_set2 = DatasetFolder(\"../input/ml2021spring-hw3/food-11/validation\", loader=lambda x: Image.open(x), extensions=\"jpg\", transform=train_tfm2)\nvalid_set = ConcatDataset([valid_set1, valid_set2])\nunlabeled_set = DatasetFolder(\"../input/ml2021spring-hw3/food-11/training/unlabeled\", loader=lambda x: Image.open(x), extensions=\"jpg\", transform=train_tfm1)\ntest_set = DatasetFolder(\"../input/ml2021spring-hw3/food-11/testing\", loader=lambda x: Image.open(x), extensions=\"jpg\", transform=test_tfm)\n\n# Construct data loaders.\ntrain_loader = DataLoader(train_set, batch_size=batch_size, shuffle=True, pin_memory=True)\nvalid_loader = DataLoader(valid_set, batch_size=batch_size, shuffle=True, pin_memory=True)\ntest_loader = DataLoader(test_set, batch_size=batch_size, shuffle=False)","metadata":{"execution":{"iopub.status.busy":"2021-09-15T08:42:34.275184Z","iopub.execute_input":"2021-09-15T08:42:34.275472Z","iopub.status.idle":"2021-09-15T08:42:44.591553Z","shell.execute_reply.started":"2021-09-15T08:42:34.27544Z","shell.execute_reply":"2021-09-15T08:42:44.590713Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"class Classifier(nn.Module):\n    def __init__(self):\n        super(Classifier, self).__init__()\n        # The arguments for commonly used modules:\n        # torch.nn.Conv2d(in_channels, out_channels, kernel_size, stride, padding)\n        # torch.nn.MaxPool2d(kernel_size, stride, padding)\n\n        # input image size: [3, 128, 128]\n        self.cnn_layers = nn.Sequential(\n            nn.Conv2d(3, 64, 3, 1, 1),\n            nn.BatchNorm2d(64),\n            nn.ReLU(),\n            nn.MaxPool2d(2, 2, 0),\n\n            nn.Conv2d(64, 128, 3, 1, 1),\n            nn.BatchNorm2d(128),\n            nn.ReLU(),\n            nn.MaxPool2d(2, 2, 0),\n\n            nn.Conv2d(128, 256, 3, 1, 1),\n            nn.BatchNorm2d(256),\n            nn.ReLU(),\n            nn.MaxPool2d(2, 2, 0),\n            \n            nn.Conv2d(256, 512, 3, 1),\n            nn.BatchNorm2d(512),\n            nn.ReLU(),\n            nn.MaxPool2d(2, 2, 0),\n\n            nn.Conv2d(512, 1024, 3, 1),\n            nn.BatchNorm2d(1024),\n            nn.ReLU(),\n            nn.MaxPool2d(2, 2, 0)\n        )\n        self.fc_layers = nn.Sequential(\n            nn.Linear(4096, 1024),\n            nn.BatchNorm1d(1024),\n            nn.ReLU(),\n            nn.Dropout(0.65),\n            #nn.Dropout(0.4),\n            nn.Linear(1024, 256),\n            nn.BatchNorm1d(256),\n            nn.ReLU(),\n            nn.Dropout(0.45),\n            nn.Linear(256, 11)\n        )\n\n    def forward(self, x):\n        # input (x): [batch_size, 3, 128, 128]\n        # output: [batch_size, 11]\n\n        # Extract features by convolutional layers.\n        x = self.cnn_layers(x)\n\n        # The extracted feature map must be flatten before going to fully-connected layers.\n        x = x.flatten(1)\n\n        # The features are transformed by fully-connected layers to obtain the final logits.\n        x = self.fc_layers(x)\n        return x","metadata":{"execution":{"iopub.status.busy":"2021-09-15T08:42:44.593048Z","iopub.execute_input":"2021-09-15T08:42:44.593396Z","iopub.status.idle":"2021-09-15T08:42:44.606285Z","shell.execute_reply.started":"2021-09-15T08:42:44.593359Z","shell.execute_reply":"2021-09-15T08:42:44.605533Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"class PseudoDataset(Dataset):\n    def __init__(self, x, y):\n        self.x = x\n        self.y = y\n\n    def __len__(self):\n        return len(self.y)\n\n    def __getitem__(self, id):\n        return self.x[id][0], self.y[id]\n\ndef get_pseudo_labels(dataset, model, threshold=0.85):\n    device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n\n    data_loader = DataLoader(dataset, batch_size=batch_size, shuffle=False)\n\n    model.eval()\n    softmax = nn.Softmax(dim=-1)\n\n    idx = []\n    labels = []\n\n    for i, batch in enumerate(data_loader):\n        img, _ = batch\n        with torch.no_grad():\n            logits = model(img.to(device))\n        probs = softmax(logits)\n\n        for j, x in enumerate(probs):\n            if torch.max(x) > threshold:\n                idx.append(i * batch_size + j)\n                labels.append(int(torch.argmax(x)))\n\n    model.train()\n    print (\"\\nNew data: {:5d}\\n\".format(len(idx)))\n    dataset = PseudoDataset(Subset(dataset, idx), labels)\n    return dataset\n\n","metadata":{"execution":{"iopub.status.busy":"2021-09-15T08:42:44.609524Z","iopub.execute_input":"2021-09-15T08:42:44.609847Z","iopub.status.idle":"2021-09-15T08:42:44.621718Z","shell.execute_reply.started":"2021-09-15T08:42:44.609821Z","shell.execute_reply":"2021-09-15T08:42:44.620899Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# \"cuda\" only when GPUs are available.\ndevice = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n\n# Initialize a model, and put it on the device specified.\nmodel = Classifier().to(device)\nmodel.device = device\n\n# For the classification task, we use cross-entropy as the measurement of performance.\ncriterion = nn.CrossEntropyLoss()\n\n# Initialize optimizer, you may fine-tune some hyperparameters such as learning rate on your own.\noptimizer = torch.optim.Adam(model.parameters(), lr=0.0003, weight_decay=1e-5)\n\n# The number of training epochs.\nn_epochs = 400\n\n# Whether to do semi-supervised learning.\ndo_semi = True\n\n# record information\nbest_acc = 0.0\ntrain_loss_record = []\nvalid_loss_record = []\ntrain_acc_record = []\nvalid_acc_record = []\nmodel_path = \"model.ckpt\"\n\nfor epoch in range(n_epochs):\n    # ---------- TODO ----------\n    # In each epoch, relabel the unlabeled dataset for semi-supervised learning.\n    # Then you can combine the labeled dataset and pseudo-labeled dataset for the training.\n    if do_semi and best_acc > 0.6 and epoch % 4 == 0:\n        # Obtain pseudo-labels for unlabeled data using trained model.\n        pseudo_set = get_pseudo_labels(unlabeled_set, model)\n        concat_dataset = ConcatDataset([train_set, pseudo_set])\n        train_loader = DataLoader(concat_dataset, batch_size=batch_size, shuffle=True, pin_memory=True, drop_last=True)\n\n\n    # ---------- Training ----------\n    # Make sure the model is in train mode before training.\n    model.train()\n\n    # These are used to record information in training.\n    train_loss = []\n    train_accs = []\n\n    # Iterate the training set by batches.\n    for batch in tqdm(train_loader):\n\n        # A batch consists of image data and corresponding labels.\n        imgs, labels = batch\n\n        # Forward the data. (Make sure data and model are on the same device.)\n        logits = model(imgs.to(device))\n\n        # Calculate the cross-entropy loss.\n        # We don't need to apply softmax before computing cross-entropy as it is done automatically.\n        loss = criterion(logits, labels.to(device))\n\n        # Gradients stored in the parameters in the previous step should be cleared out first.\n        optimizer.zero_grad()\n\n        # Compute the gradients for parameters.\n        loss.backward()\n\n        # Clip the gradient norms for stable training.\n        grad_norm = nn.utils.clip_grad_norm_(model.parameters(), max_norm=10)\n\n        # Update the parameters with computed gradients.\n        optimizer.step()\n\n        # Compute the accuracy for current batch.\n        acc = (logits.argmax(dim=-1) == labels.to(device)).float().mean()\n\n        # Record the loss and accuracy.\n        train_loss.append(loss.item())\n        train_accs.append(acc)\n\n    # The average loss and accuracy of the training set is the average of the recorded values.\n    train_loss = sum(train_loss) / len(train_loss)\n    train_acc = sum(train_accs) / len(train_accs)\n\n    # Print the information.\n    print(f\"[ Train | {epoch + 1:03d}/{n_epochs:03d} ] loss = {train_loss:.5f}, acc = {train_acc:.5f}\")\n\n    # ---------- Validation ----------\n    # Make sure the model is in eval mode so that some modules like dropout are disabled and work normally.\n    model.eval()\n\n    # These are used to record information in validation.\n    valid_loss = []\n    valid_accs = []\n\n    # Iterate the validation set by batches.\n    for batch in tqdm(valid_loader):\n\n        # A batch consists of image data and corresponding labels.\n        imgs, labels = batch\n\n        # We don't need gradient in validation.\n        # Using torch.no_grad() accelerates the forward process.\n        with torch.no_grad():\n          logits = model(imgs.to(device))\n\n        # We can still compute the loss (but not the gradient).\n        loss = criterion(logits, labels.to(device))\n\n        # Compute the accuracy for current batch.\n        acc = (logits.argmax(dim=-1) == labels.to(device)).float().mean()\n\n        # Record the loss and accuracy.\n        valid_loss.append(loss.item())\n        valid_accs.append(acc)\n\n    # The average loss and accuracy for entire validation set is the average of the recorded values.\n    valid_loss = sum(valid_loss) / len(valid_loss)\n    valid_acc = sum(valid_accs) / len(valid_accs)\n    # Print the information.\n    print(f\"[ Valid | {epoch + 1:03d}/{n_epochs:03d} ] loss = {valid_loss:.5f}, acc = {valid_acc:.5f}\")\n    # ------Record every time information------\n    if valid_acc > best_acc:\n        best_acc = valid_acc\n        torch.save(model.state_dict(), model_path)\n    train_loss_record.append(train_loss)\n    valid_loss_record.append(valid_loss)\n    train_acc_record.append(train_acc)\n    valid_acc_record.append(valid_acc)","metadata":{"execution":{"iopub.status.busy":"2021-09-15T08:42:44.624891Z","iopub.execute_input":"2021-09-15T08:42:44.625173Z"},"trusted":true},"execution_count":null,"outputs":[]}]}